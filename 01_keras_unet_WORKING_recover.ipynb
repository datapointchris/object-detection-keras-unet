{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from callbacks import ValPlotCallback\n",
    "from model import make_model\n",
    "from keras.layers import Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# from tqdm.keras import TqdmCallback\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import numpy as np\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from helpers import image_splitter, print_array_properties, image_checker, image_tester, create_batches, batch_stacker\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_dir = 'images/training/build/0/'\n",
    "train_mask_dir = 'images/training/mask/0/'\n",
    "test_image_dir = 'images/training/test/0/'\n",
    "data_dir = 'data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 77\n",
    "\n",
    "# ======Image Splitter Params ====== #\n",
    "split_rows = 200\n",
    "split_cols = 200\n",
    "resize = True\n",
    "image_resize_width = 240\n",
    "image_resize_height = 240\n",
    "\n",
    "images_per_batch = 64  # decrease this number if running out of memory\n",
    "train_val_split_size = 0.1\n",
    "# ======================= MODEL PARAMS ======================= #\n",
    "epochs = 20\n",
    "model_batch_size = 64\n",
    "model_name = 'datagenmodel'\n",
    "model_path = os.path.join(data_dir, model_name + '.hdf5')\n",
    "pretrained_model = True\n",
    "pretrained_model_path = model_path\n",
    "print_model_summary_on_compile = False\n",
    "plot_epoch_val_images = True\n",
    "\n",
    "# ==================== Data Augmentation ==================== #\n",
    "data_augmentation = True\n",
    "datagen_args = dict(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "    # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    rotation_range=60,\n",
    "    # randomly shift images horizontally (fraction of total width)\n",
    "    width_shift_range=0.2,\n",
    "    # randomly shift images vertically (fraction of total height)\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.0,  # set range for random shear\n",
    "    zoom_range=0.0,  # set range for random zoom\n",
    "    channel_shift_range=0.0,  # set range for random channel shifts\n",
    "    # set mode for filling points outside the input boundaries\n",
    "    fill_mode='nearest',\n",
    "    cval=0.0,  # value used for fill_mode = \"constant\"\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=True,  # randomly flip images\n",
    "    # set rescaling factor (applied before any other transformation)\n",
    "    rescale=None,\n",
    "    # set function that will be applied on each input\n",
    "    preprocessing_function=None,\n",
    "    # image data format, either \"channels_first\" or \"channels_last\"\n",
    "    data_format='channels_last',\n",
    "    # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "    validation_split=0.0,\n",
    ")\n",
    "\n",
    "# ==================== Callbacks ==================== #\n",
    "early_stop = EarlyStopping(patience=5, verbose=1)\n",
    "check_point = ModelCheckpoint(\n",
    "    os.path.join(data_dir, model_name + '.hdf5'), save_best_only=True, verbose=1\n",
    ")\n",
    "tensor_board = TensorBoard(\n",
    "    log_dir='../logs/tensorboard/',\n",
    "    histogram_freq=1,\n",
    "    write_graph=True,\n",
    "    write_grads=False,\n",
    "    write_images=True,\n",
    "    embeddings_freq=1,\n",
    "    update_freq='epoch',\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BATCH NUMBER 1\n",
      "==========\n",
      "X_TRAIN\n",
      "Length: 57\n",
      "Shape: (57, 240, 240, 3)\n",
      "Size: 0.037 GB\n",
      "==========\n",
      "\n",
      "==========\n",
      "Y_TRAIN\n",
      "Length: 57\n",
      "Shape: (57, 240, 240, 1)\n",
      "Size: 0.012 GB\n",
      "==========\n",
      "\n",
      "==========\n",
      "X_VAL\n",
      "Length: 7\n",
      "Shape: (7, 240, 240, 3)\n",
      "Size: 0.005 GB\n",
      "==========\n",
      "\n",
      "==========\n",
      "Y_VAL\n",
      "Length: 7\n",
      "Shape: (7, 240, 240, 1)\n",
      "Size: 0.002 GB\n",
      "==========\n",
      "\n",
      "Loading Trained Model\n",
      "Augmenting Data\n",
      "Epoch 1/20\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.5631 - accuracy: 0.6766\n",
      "Epoch 1: val_loss improved from inf to 0.50869, saving model to data/datagenmodel.hdf5\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.5631 - accuracy: 0.6766 - val_loss: 0.5087 - val_accuracy: 0.7820\n",
      "Epoch 2/20\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4488 - accuracy: 0.7104\n",
      "Epoch 2: val_loss improved from 0.50869 to 0.48748, saving model to data/datagenmodel.hdf5\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.4488 - accuracy: 0.7104 - val_loss: 0.4875 - val_accuracy: 0.7918\n",
      "Epoch 3/20\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.4614 - accuracy: 0.6963\n",
      "Epoch 3: val_loss did not improve from 0.48748\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.4614 - accuracy: 0.6963 - val_loss: 0.5045 - val_accuracy: 0.7810\n",
      "Epoch 4/20\n"
     ]
    }
   ],
   "source": [
    "train_path = Path(train_image_dir)\n",
    "mask_path = Path(train_mask_dir)\n",
    "\n",
    "filenames = sorted([f.name for f in train_path.glob('*.tif')])\n",
    "# print(filenames)\n",
    "\n",
    "train_files = [str(train_path / name) for name in filenames]\n",
    "mask_files = [str(mask_path / name) for name in filenames]\n",
    "\n",
    "# train = list(train)\n",
    "# mask = list(mask)\n",
    "# print('images', len(train))\n",
    "\n",
    "train_img_batches = create_batches(train_files, batch_size=images_per_batch)\n",
    "train_mask_batches = create_batches(mask_files, batch_size=images_per_batch)\n",
    "# train_img_batches = list(train_img_batches)\n",
    "# train_mask_batches = list(train_mask_batches)\n",
    "# print('batches', len(train_img_batches))\n",
    "\n",
    "train_stack = batch_stacker(train_img_batches, resize=(image_resize_width, image_resize_width))\n",
    "mask_stack = batch_stacker(train_mask_batches, resize=(image_resize_width, image_resize_width), gray=True)\n",
    "# train_stack = list(train_stack)\n",
    "# mask_stack = list(mask_stack)\n",
    "# print('stack', len(train_stack))\n",
    "\n",
    "\n",
    "for batch_number, (train_batch, mask_batch) in enumerate(zip(train_stack, mask_stack), start=1):\n",
    "    print(f'BATCH NUMBER {batch_number}')\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(\n",
    "        train_batch, mask_batch, random_state=SEED, test_size=train_val_split_size\n",
    "    )\n",
    "    if batch_number == 1:\n",
    "        print_array_properties('x_train', x_train)\n",
    "        print_array_properties('y_train', y_train)\n",
    "        print_array_properties('x_val', x_val)\n",
    "        print_array_properties('y_val', y_val)\n",
    "\n",
    "    inputs = Input(shape=(x_train.shape[1:]))\n",
    "    \n",
    "    if pretrained_model or batch_number > 1:\n",
    "        print('Loading Trained Model')\n",
    "        model = load_model(pretrained_model_path)\n",
    "    else:\n",
    "        print('Creating New Model')\n",
    "        model = make_model(inputs=inputs, model_name=model_name, print_summary=False)\n",
    "\n",
    "    # =================== MODEL PARAMS =================== #\n",
    "    validation_plots = ValPlotCallback(model, model_batch_size, x_val, y_val)\n",
    "    model_fit_params = dict(\n",
    "        batch_size=model_batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(x_val, y_val),\n",
    "        verbose=1,\n",
    "        steps_per_epoch=max(x_train.shape[0] // model_batch_size, 1),\n",
    "        validation_steps=max((x_train.shape[0] // model_batch_size) * train_val_split_size, 1),\n",
    "        callbacks=[early_stop, check_point, tensor_board, validation_plots],\n",
    "    )\n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        model.fit(x_train, y_train, **model_fit_params)\n",
    "    else:\n",
    "        print('Augmenting Data')\n",
    "\n",
    "        # provide the same seed and keyword arguments\n",
    "        image_datagen = ImageDataGenerator(**datagen_args)\n",
    "        mask_datagen = ImageDataGenerator(**datagen_args)\n",
    "\n",
    "        image_datagen.fit(x_train, augment=True, seed=SEED)\n",
    "        mask_datagen.fit(y_train, augment=True, seed=SEED)\n",
    "\n",
    "        # save_to_dir='../images/augmented/images/',\n",
    "        # save_to_dir='../images/augmented/masks/',\n",
    "        image_generator = image_datagen.flow(x_train, seed=SEED)\n",
    "        mask_generator = mask_datagen.flow(y_train, seed=SEED)\n",
    "\n",
    "        train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "        model.fit(train_generator, **model_fit_params)\n",
    "        if batch_number == 1:\n",
    "            # otherwise possibly load an old model on second epoch\n",
    "            model.save(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================ #\n",
    "# ========================== VALIDATION ========================== #\n",
    "\n",
    "x_val_pred = model.predict(x_val, verbose=1, batch_size=model_batch_size)\n",
    "\n",
    "model.evaluate(x=x_val, y=y_val, batch_size=model_batch_size)\n",
    "\n",
    "# simple threshold to change to 1/0, mask\n",
    "x_val_pred_mask = (x_val_pred > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(original=x_val, predicted=x_val_pred,\n",
    "                 predicted_mask=x_val_pred_mask, ground_truth=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('../data/testing_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================ #\n",
    "# ========================== PREDICTION ========================== #\n",
    "\n",
    "\n",
    "x_test = [np.array(\n",
    "    image_splitter(\n",
    "        cv2.imread(test_image_dir + img_name).astype(np.uint8),\n",
    "        num_col_splits=split_cols,\n",
    "        num_row_splits=split_rows,\n",
    "        resize=resize,\n",
    "        resize_height=image_resize_height,\n",
    "        resize_width=image_resize_width\n",
    "    )\n",
    ") for img_name in tqdm(test_filenames[:20])]\n",
    "\n",
    "x_test = (np.vstack(x_test)/255).astype(np.float32)\n",
    "\n",
    "shape_and_mem(x_test)\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow(x_test, seed=seed)\n",
    "\n",
    "y_pred = model.predict(test_generator, verbose=1)\n",
    "\n",
    "shape_and_mem(y_pred)\n",
    "\n",
    "y_pred_mask = (y_pred > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_predictions(original=x_test, predicted=y_pred,\n",
    "                 predicted_mask=y_pred_mask)\n",
    "\n",
    "\n",
    "# https://www.jeremyjordan.me/evaluating-image-segmentation-models/\n",
    "\n",
    "# result = cv2.bitwise_and(test_split[0], test_split[0], mask=prediction[0])\n",
    "\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2\n",
    "\n",
    "# https://www.jeremyjordan.me/evaluating-image-segmentation-models/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7cca29d56564b7cec1d60ca6d75a12513a3462fa36dc05318b6fa4375581983a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
