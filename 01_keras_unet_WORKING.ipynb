{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "https://www.kaggle.com/christofhenkel/keras-baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#########################################################################\n",
    "# CURRENTLY WORKING WITH TENSORFLOW\n",
    "# \n",
    "# PRIORITIES:\n",
    "# 1. refactor code to better groupings\n",
    "# 2. where do the functions go\n",
    "# 3. grab validation data\n",
    "# 4. test testing data generator\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "\n",
    "# ====================================== #\n",
    "### CURRENT WORKING IMAGE INPUT PARAMS ###\n",
    "\n",
    "# IMAGES_PER_BATCH\n",
    "# original images loaded and vstacked\n",
    "# 16 images = 23 GB\n",
    "# 8 images is faster\n",
    "\n",
    "# MODEL_BATCH_SIZE\n",
    "# how many of the splitter output arrays to process at one time\n",
    "# 128 = ERROR\n",
    "# 96 is okay\n",
    "\n",
    "# SPLITS\n",
    "# row X col = total images into array\n",
    "# more splits = larger batch size\n",
    "\n",
    "### GOOD ###\n",
    "images_per_batch = 16\n",
    "split_rows = 20\n",
    "split_cols = 20\n",
    "model_batch_size = 96\n",
    "augmentation = False\n",
    "\n",
    "### NOT GOOD ###\n",
    "images_per_batch = 16\n",
    "split_rows = 20\n",
    "split_cols = 20\n",
    "model_batch_size = 96\n",
    "augmentation = True\n",
    "# with augmentation 28 GB used memory, going into swap\n",
    "\n",
    "### NOT GOOD ###\n",
    "images_per_batch = 16\n",
    "split_rows = 24\n",
    "split_cols = 24\n",
    "model_batch_size = 128\n",
    "augmentation = True\n",
    "# batch size too large to fit in GPU\n",
    "\n",
    "\n",
    "# ====================================== #\n",
    "\n",
    "\n",
    "# # ======================================== FOR RUNNING ON THE MACBOOK PRO ====================\n",
    "\n",
    "### TODO ###\n",
    "# Check for MacOS environment to enable this automatically\n",
    "\n",
    "# ## DO THIS BEFORE IMPORTING KERAS OR TENSOR TO USE PLAIDML\n",
    "# import plaidml.keras\n",
    "# plaidml.keras.install_backend()\n",
    "\n",
    "# # Help MacOS be able to use Keras\n",
    "# import os\n",
    "# os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "\n",
    "# # Gets rid of the processor warning.\n",
    "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Input, BatchNormalization, Lambda\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, concatenate, Concatenate, Conv2DTranspose, UpSampling2D\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# from tqdm.keras import TqdmCallback\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import skimage.io\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# ============================================================================ #\n",
    "# ======================= PARAMETERS, PATHS, VARIABLES ======================= #\n",
    "# ============================================================================ #\n",
    "\n",
    "train_image_dir = '../images/network_training/build/0/'\n",
    "train_mask_dir = '../images/network_training/mask/0/'\n",
    "test_image_dir = '../images/network_training/test/0/'\n",
    "data_dir = '../data/'\n",
    "\n",
    "train_images = glob.glob(train_image_dir + '*')\n",
    "train_filenames = [os.path.basename(x) for x in train_images]\n",
    "\n",
    "test_images = glob.glob(test_image_dir + '*')\n",
    "test_filenames = [os.path.basename(x) for x in test_images]\n",
    "\n",
    "\n",
    "# decrease this number if running out of memory\n",
    "\n",
    "images_per_batch = 8\n",
    "\n",
    "# val split from training set\n",
    "train_val_split_size = .1\n",
    "\n",
    "seed = 77\n",
    "\n",
    "\n",
    "# ======Image Splitter Params ====== #\n",
    "\n",
    "split_rows = 20\n",
    "split_cols = 20\n",
    "resize = True\n",
    "image_resize_width = 4800\n",
    "image_resize_height = 4800\n",
    "\n",
    "\n",
    "# ==================================== MODEL PARAMS ==================================== #\n",
    "epochs = 10\n",
    "model_batch_size = 64\n",
    "model_name = 'datagenmodel'\n",
    "model_path = os.path.join(data_dir, model_name + '.h5')\n",
    "pretrained_model = True\n",
    "\n",
    "pretrained_model_path = model_path\n",
    "\n",
    "print_model_summary_on_compile = False\n",
    "\n",
    "plot_epoch_val_images = True\n",
    "\n",
    "\n",
    "# ==================== Callbacks ==================== #\n",
    "\n",
    "class ValPlotCallback(Callback):\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print('VALIDATION IMAGES')\n",
    "        x_val_pred = model.predict(x_val, verbose=1, batch_size=model_batch_size)\n",
    "        x_val_pred_mask = (x_val_pred > 0.5).astype(np.uint8)\n",
    "        plot_predictions(original=x_val,\n",
    "                         predicted=x_val_pred,\n",
    "                         predicted_mask=x_val_pred_mask,\n",
    "                         ground_truth=y_val,\n",
    "                         repeat=True)\n",
    "\n",
    "validation_plots = ValPlotCallback()\n",
    "early_stop = EarlyStopping(patience=5, verbose=1)\n",
    "check_point = ModelCheckpoint(os.path.join(data_dir, model_name + '.hdf5'),\n",
    "                              save_best_only=True,verbose=1)\n",
    "tensor_board = TensorBoard(log_dir='../logs/tensorboard/', histogram_freq=1, \n",
    "                            write_graph=True, write_grads=False, \n",
    "                            write_images=True, embeddings_freq=1, update_freq='epoch')\n",
    "\n",
    "\n",
    "# ==================== Data Augmentation ==================== #                        \n",
    "data_augmentation = True\n",
    "datagen_args = dict(featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "                             samplewise_center=False,  # set each sample mean to 0\n",
    "                             featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "                             samplewise_std_normalization=False,  # divide each input by its std\n",
    "                             zca_whitening=False,  # apply ZCA whitening\n",
    "                             zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "                             # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                             rotation_range=60,\n",
    "                             # randomly shift images horizontally (fraction of total width)\n",
    "                             width_shift_range=0.2,\n",
    "                             # randomly shift images vertically (fraction of total height)\n",
    "                             height_shift_range=0.2,\n",
    "                             shear_range=0.,  # set range for random shear\n",
    "                             zoom_range=0.,  # set range for random zoom\n",
    "                             channel_shift_range=0.,  # set range for random channel shifts\n",
    "                             # set mode for filling points outside the input boundaries\n",
    "                             fill_mode='nearest',\n",
    "                             cval=0.,  # value used for fill_mode = \"constant\"\n",
    "                             horizontal_flip=True,  # randomly flip images\n",
    "                             vertical_flip=True,  # randomly flip images\n",
    "                             # set rescaling factor (applied before any other transformation)\n",
    "                             rescale=None,\n",
    "                             # set function that will be applied on each input\n",
    "                             preprocessing_function=None,\n",
    "                             # image data format, either \"channels_first\" or \"channels_last\"\n",
    "                             data_format='channels_last',\n",
    "                             # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "                             validation_split=0.0)                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValPlotCallback(Callback):\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        print('VALIDATION IMAGES')\n",
    "        x_val_pred = model.predict(x_val, verbose=1, batch_size=model_batch_size)\n",
    "        x_val_pred_mask = (x_val_pred > 0.5).astype(np.uint8)\n",
    "        plot_predictions(original=x_val,\n",
    "                         predicted=x_val_pred,\n",
    "                         predicted_mask=x_val_pred_mask,\n",
    "                         ground_truth=y_val,\n",
    "                         repeat=True)\n",
    "\n",
    "def load_image_as_array(image_name, image_dir, gray=False, resize=False):\n",
    "    \"\"\"\n",
    "    Loads and splits an image\n",
    "    Returns numpy array\n",
    "    \"\"\"\n",
    "    if gray is False:\n",
    "        image = cv2.imread(image_dir + image_name).astype(np.uint8)\n",
    "    else:\n",
    "        image = cv2.imread(image_dir + image_name, 0).astype(np.uint8)\n",
    "\n",
    "    image_as_array = image_splitter(image,\n",
    "                                 num_col_splits=split_cols,\n",
    "                                 num_row_splits=split_rows,\n",
    "                                 resize=resize,\n",
    "                                 resize_height=image_resize_height,\n",
    "                                 resize_width=image_resize_width)\n",
    "    return image_as_array\n",
    "\n",
    "def shape_and_mem(array):\n",
    "    \"\"\"Prints the shape and memory size of an array\"\"\"\n",
    "    print(f'Shape: {array.shape}')\n",
    "    print(f'Size: {round(array.itemsize * array.size / 1024 / 1024 / 1024, 3)} GB')\n",
    "\n",
    "def image_splitter(image, num_col_splits, num_row_splits, resize=False, resize_width=None, resize_height=None):\n",
    "    \"\"\"\n",
    "    Splits an image into 'num_col_splits' X 'num_row_splits'\n",
    "    Resize by setting resize=True and specifying 'resize_width' and 'resize_height'\n",
    "    Returns array of images arranged from left -> right, top -> bottom\n",
    "    \"\"\"\n",
    "    if resize:\n",
    "        image = cv2.resize(image, (resize_width, resize_height))\n",
    "    \n",
    "    width = image.shape[0] \n",
    "    height = image.shape[1]\n",
    "    imglist = []\n",
    "\n",
    "    for startpoint in np.linspace(0,width,num_col_splits, endpoint=False):\n",
    "        endpoint=startpoint + (width / num_col_splits)\n",
    "\n",
    "        for startp2 in np.linspace(0,height,num_row_splits, endpoint=False):\n",
    "            endp2=startp2 + (height / num_row_splits)\n",
    "\n",
    "            imglist.append(image[int(startp2):int(endp2), int(startpoint):int(endpoint)]\n",
    "                        )\n",
    "    return np.array(imglist)\n",
    "\n",
    "def image_tester(original):\n",
    "    \"\"\"Shows original images in array\"\"\"\n",
    "    for _ in range(4):\n",
    "        ix = np.random.randint(0, original.shape[0])\n",
    "        fig, ax = plt.subplots(figsize=(10, 24))\n",
    "\n",
    "        ax.set_title('Original')\n",
    "        ax.imshow(original[ix])\n",
    "        ax.axis('off')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "def image_checker(original, ground_truth):\n",
    "    \"\"\"Shows original images in array with their ground truth masks\"\"\"\n",
    "    for _ in range(4):\n",
    "        ix = np.random.randint(0, original.shape[0])\n",
    "        fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(10, 24))\n",
    "\n",
    "        ax1.set_title('Original')\n",
    "        ax1.imshow(original[ix])\n",
    "        ax1.axis('off')\n",
    "\n",
    "        ax2.set_title('Ground Truth')\n",
    "        ax2.imshow(np.squeeze(ground_truth[ix]))\n",
    "        ax2.axis('off')    \n",
    "\n",
    "        plt.subplots_adjust(wspace=.3, hspace=.3)\n",
    "        plt.show()\n",
    "\n",
    "def make_model(pretrained_model=False, model_name=model_name, summary=print_model_summary_on_compile):\n",
    "    '''\n",
    "    Creates a new U-Net model\n",
    "    '''\n",
    "    inputs = Input((x_train.shape[1], x_train.shape[2], 3))\n",
    "    s = Lambda(lambda x: x) (inputs) # removed / 255\n",
    "\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n",
    "    c1 = Dropout(0.1) (c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "    c2 = Dropout(0.1) (c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "    c3 = Dropout(0.2) (c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "    c4 = Dropout(0.2) (c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "    c5 = Dropout(0.3) (c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "    c6 = Dropout(0.2) (c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "    c7 = Dropout(0.2) (c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "    c8 = Dropout(0.1) (c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "    c9 = Dropout(0.1) (c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    if summary is not None:\n",
    "        print(summary())\n",
    "    \n",
    "    return model\n",
    "\n",
    "def plot_predictions(original, predicted, predicted_mask, ground_truth=None, repeat=False):\n",
    "    \"\"\"\n",
    "    Plots the original image, predicted image, mask from the predicted image, and ground truth mask.\n",
    "    ground_truth: None for testing images without masks\n",
    "    repeat: use the same first 4 images in the dataset for comparison\n",
    "    \"\"\"\n",
    "    ncols_calc = 3\n",
    "    if ground_truth is not None:\n",
    "        ncols_calc = 4\n",
    "        \n",
    "    \n",
    "    for i in range(4):\n",
    "        if repeat:\n",
    "            ix = i\n",
    "        else:\n",
    "            ix = np.random.randint(0, predicted.shape[0])\n",
    "            \n",
    "        fig, ax = plt.subplots(ncols=ncols_calc, figsize=(ncols_calc*5, 24))\n",
    "\n",
    "        ax[0].set_title('Original')\n",
    "        ax[0].imshow(original[ix])\n",
    "        ax[0].axis('off')\n",
    "\n",
    "        ax[1].set_title('Predicted')\n",
    "        ax[1].imshow(np.squeeze(predicted[ix]))\n",
    "        ax[1].axis('off')    \n",
    "\n",
    "        ax[2].set_title('Predicted Mask')\n",
    "        ax[2].imshow(np.squeeze(predicted_mask[ix]))\n",
    "        ax[2].axis('off')\n",
    "        \n",
    "        if ground_truth is not None:\n",
    "            ax[3].set_title('Ground Truth')\n",
    "            ax[3].imshow(np.squeeze(ground_truth[ix]))\n",
    "            ax[3].axis('off')\n",
    "\n",
    "        plt.subplots_adjust(wspace=.3, hspace=.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ======================= IMAGE PROCESSING ======================= #\n",
    "# ================================================================ #\n",
    "\n",
    "\n",
    "# create batch sets of 'images_per_batch' size\n",
    "training_sets = [train_filenames[i:i + images_per_batch]\n",
    "                 for i in range(0, len(train_filenames), images_per_batch)]\n",
    "\n",
    "# load images in batch as a list of arrays\n",
    "for batch_number, train_set in enumerate(tqdm(training_sets), start=1):\n",
    "    print(f'BATCH NUMBER {batch_number} of {len(training_sets)}')\n",
    "    xlist = []\n",
    "    ylist = []\n",
    "    for name in tqdm(train_set):\n",
    "        xlist.append(load_image_as_array(name, train_image_dir, resize=True))\n",
    "        ylist.append(load_image_as_array(name, train_mask_dir, resize=True, gray=True))\n",
    "\n",
    "    print('loadedimages')\n",
    "    print('xlist')\n",
    "    print(len(xlist))\n",
    "    print(xlist[0].shape)\n",
    "    print('ylist')\n",
    "    print(len(ylist))\n",
    "    print(ylist[0].shape)\n",
    "\n",
    "    x = (np.vstack(xlist)/255).astype(np.float32)\n",
    "    y = (np.vstack(ylist)/255).astype(np.float32)\n",
    "    y = np.expand_dims(y, axis=3)  # grayscale\n",
    "\n",
    "    print('stacked images')\n",
    "    print('x and y')\n",
    "    print(shape_and_mem(x))\n",
    "    print(shape_and_mem(y))\n",
    "\n",
    "    x_train, x_val, y_train, y_val = train_test_split(x, y,\n",
    "                                                      random_state=77,\n",
    "                                                      test_size=train_val_split_size)\n",
    "    print('xtrain, ytrain, xval, yval')\n",
    "    print(shape_and_mem(x_train))\n",
    "    print(shape_and_mem(y_train))\n",
    "    print(shape_and_mem(x_val))\n",
    "    print(shape_and_mem(y_val))\n",
    "\n",
    "    # ================================================================ #\n",
    "    # =========================== TRAINING =========================== #\n",
    "    \n",
    "    # load or train model\n",
    "    if pretrained_model or batch_number > 1:\n",
    "        print('Loading Trained Model')\n",
    "        model = load_model(trained_model)\n",
    "    else:\n",
    "        print('Creating New Model')\n",
    "        model = make_model(pretrained_model=pretrained_model,\n",
    "                           model_name=model_name)\n",
    "        \n",
    "    # =================== MODEL PARAMS =================== #\n",
    "    model_fit_params = dict(batch_size=model_batch_size,\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        verbose=1,\n",
    "                        steps_per_epoch=x_train.shape[0] // model_batch_size,\n",
    "                        validation_steps=(x_train.shape[0] // model_batch_size) * train_val_split_size,\n",
    "                        callbacks=[early_stop, check_point, tensor_board, validation_plots])\n",
    "        \n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        model.fit(x_train, y_train, **model_fit_params)\n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "\n",
    "        image_datagen = ImageDataGenerator(**datagen_args)\n",
    "        mask_datagen = ImageDataGenerator(**datagen_args)\n",
    "\n",
    "        # provide the same seed and keyword arguments\n",
    "        image_datagen.fit(x_train, augment=True, seed=seed)\n",
    "        mask_datagen.fit(y_train, augment=True, seed=seed)\n",
    "\n",
    "        image_generator = image_datagen.flow(x_train,\n",
    "        #                                    save_to_dir='../images/augmented/images/',\n",
    "                                             seed=seed)\n",
    "\n",
    "        mask_generator = mask_datagen.flow(y_train,\n",
    "        #                                  save_to_dir='../images/augmented/masks/',\n",
    "                                           seed=seed)\n",
    "        ### NOTE ###\n",
    "        # Can I use the validation setting on the image generators and get rid of the train/test split\n",
    "        # then I can feed my images in as generators to the generators and skip the loop\n",
    "        \n",
    "        # combine generators into one which yields image and masks\n",
    "        train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "        model.fit(train_generator, **model_fit_params)\n",
    "\n",
    "    model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================ #\n",
    "# ========================== VALIDATION ========================== #\n",
    "\n",
    "x_val_pred = model.predict(x_val, verbose=1, batch_size=model_batch_size)\n",
    "\n",
    "model.evaluate(x=x_val, y=y_val, batch_size=model_batch_size)\n",
    "\n",
    "# simple threshold to change to 1/0, mask\n",
    "x_val_pred_mask = (x_val_pred > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(original=x_val, predicted=x_val_pred,\n",
    "                 predicted_mask=x_val_pred_mask, ground_truth=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = load_model('../data/testing_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================================================ #\n",
    "# ========================== PREDICTION ========================== #\n",
    "\n",
    "\n",
    "x_test = [np.array(\n",
    "    image_splitter(\n",
    "        cv2.imread(test_image_dir + img_name).astype(np.uint8),\n",
    "        num_col_splits=split_cols,\n",
    "        num_row_splits=split_rows,\n",
    "        resize=resize,\n",
    "        resize_height=image_resize_height,\n",
    "        resize_width=image_resize_width\n",
    "    )\n",
    ") for img_name in tqdm(test_filenames[:20])]\n",
    "\n",
    "x_test = (np.vstack(x_test)/255).astype(np.float32)\n",
    "\n",
    "shape_and_mem(x_test)\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "test_generator = test_datagen.flow(x_test, seed=seed)\n",
    "\n",
    "y_pred = model.predict(test_generator, verbose=1)\n",
    "\n",
    "shape_and_mem(y_pred)\n",
    "\n",
    "y_pred_mask = (y_pred > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_predictions(original=x_test, predicted=y_pred,\n",
    "                 predicted_mask=y_pred_mask)\n",
    "\n",
    "\n",
    "# https://www.jeremyjordan.me/evaluating-image-segmentation-models/\n",
    "\n",
    "# result = cv2.bitwise_and(test_split[0], test_split[0], mask=prediction[0])\n",
    "\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://towardsdatascience.com/metrics-to-evaluate-your-semantic-segmentation-model-6bcb99639aa2\n",
    "\n",
    "# https://www.jeremyjordan.me/evaluating-image-segmentation-models/\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
